Day 12 - Depth8 Circle Classification 
Loss observation : 
(C1) Global Trend : 
-Exhibits an overall decreasing trend with noticeably higher fluctuations compared to shallower depths.
(C2) Stability : 
-Relatively stable overall, but is the most oscillatory and exhibits the highest frequency of spikes among all models evaluated on the circle classification task.
-This behavior is likely attributed to the increased optimization cost introduced by greater network depth under a fixed training budget of 1000 epochs.
(C3) Plateau Phase: 
-A plateau-like behavior is observed after approximately 100 epochs.
(C4) Late-stage gain: 
-No meaningful late-stage improvement is observed, consistent with the behavior seen in shallower deep models.


RAW LOST SAMPLES(LAST 100 EPOCHS): loss samples fluctuate slightly within a bounded(the largest bound so far) ,with regular spikes
(THESE SAMPLES ARE REPRESENTATIVE)
0.0038   0.0166   0.0090   0.0057   0.0056   0.0126   0.0049   0.0045   0.0053   0.0076
  0.0050   0.0057   0.0082   0.0118   0.0059   0.0055   0.0087   0.0069   0.0097   0.0051
  0.0039   0.0050   0.0071   0.0050   0.0041   0.0030   0.0034   0.0084   0.0049   0.0057
  0.0045   0.0095   0.0050   0.0235   0.0098   0.0070   0.0056   0.0052   0.0043   0.0058
  0.0050   0.0097   0.0094   0.0038   0.0054   0.0038   0.0070   0.0061   0.0068   0.0071
  0.0033   0.0090   0.0087   0.0187   0.0045   0.0058   0.0105   0.0044   0.0062   0.0034
  0.0038   0.0043   0.0056   0.0026   0.0091   0.0055   0.0028   0.0103   0.0153   0.0052
  0.0039   0.0060   0.0061   0.0095   0.0041   0.0219   0.0042   0.0046   0.0038   0.0078
  0.0048   0.0055   0.0055   0.0082   0.0111   0.0098   0.0045   0.0059   0.0046   0.0140
  0.0044   0.0065   0.0079   0.0059   0.0050   0.0063   0.0137   0.0045   0.0063   0.0051
(C5) Minimal Interpretation : 
-the loss shows no considerable features beyond approximately 100 epochs, no late-state gains are obtained

WRITTEN OBSERVATION: 
Under a fixed training budget, the depth-8 model follows a convergence pattern similar in timing to shallower architectures, reaching a plateau at approximately 100 epochs. However, the loss trajectory exhibits the highest variability observed so far, with frequent oscillations and occasional spikes during late training stages.
Despite increased representational depth, no measurable late-stage gains are achieved, suggesting that additional depth primarily increases optimization difficulty rather than improving final convergence behavior under the current training constraints.


TRAIN ACCURACY(MEAN OF 10 RUNS): 0.9981 ± 0.0012
TEST  ACCURACY(MEAN OF 10 RUNS): 0.9935 ± 0.0044





