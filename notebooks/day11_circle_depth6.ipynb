{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e5b1a9-77d2-4fc8-9cc0-714223c15bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "PROJECT_ROOT = os.path.abspath(\"..\")\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from module.dynamic_architect import Neural_Network\n",
    "from module.layers import Linear\n",
    "from module.activations import ReLU, Sigmoid\n",
    "from module.losses import BCE\n",
    "from module.train_loop import train\n",
    "from data.generate import generate_circle_data\n",
    "\n",
    "def Predict(X,model): \n",
    "    A = X \n",
    "    for layer in model: \n",
    "        A = layer.forward(A) \n",
    "    return A\n",
    "train_accs = []\n",
    "test_accs = []\n",
    "\n",
    "\n",
    "\n",
    "for seed in range(10):\n",
    "    \n",
    "    np.set_printoptions(suppress=True) \n",
    "    depth6 = Neural_Network([2,16,16,16,16,16,16,1]) \n",
    "    model = depth6.layers \n",
    "    X,y =  generate_circle_data(2000,0.5,seed)\n",
    "    loss_func = BCE()\n",
    "    loss_history = train(model,loss_func,X,y,1000,32,0.001) \n",
    "    \n",
    "    \n",
    "    \n",
    "  \n",
    "    y_hat = Predict(X,model) \n",
    "    y_pred = (y_hat > 0.5).astype(int)\n",
    "    training_accuracy = np.mean(y_pred == y)\n",
    "    \n",
    "    \n",
    "    X_test,y_test =  generate_circle_data(400,0.5,seed+100)\n",
    "    y_hat_test = Predict(X_test,model)\n",
    "    y_pred_test = (y_hat_test > 0.5).astype(int)\n",
    "    testing_accuracy = np.mean(y_pred_test == y_test)\n",
    "    \n",
    "    train_accs.append(training_accuracy)\n",
    "    test_accs.append(testing_accuracy)\n",
    "\n",
    "print(f\"TRAIN acc: {np.mean(train_accs):.4f} ± {np.std(train_accs):.4f}\")\n",
    "print(f\"TEST  acc: {np.mean(test_accs):.4f} ± {np.std(test_accs):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b51070-6f08-4a92-a371-5aaf874a6f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_per_epoch = int(np.ceil(len(X) / 32))\n",
    "epoch_loss = [\n",
    "    np.mean(loss_history[i*batch_per_epoch:(i+1)*batch_per_epoch])\n",
    "    for i in range(1000)\n",
    "]\n",
    "import matplotlib.pyplot as plt \n",
    "plt.plot(epoch_loss)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Mean Training Loss\") \n",
    "plt.title(\"Training loss Curve(depth=6)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2084af-cbc2-45f9-82bc-2da2135c2205",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_100 = epoch_loss[900:]\n",
    "for i in range(0,100,10): \n",
    "    print(\" \".join(f\"{x:8.4f}\" for x in last_100[i:i+10]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my_rl_env)",
   "language": "python",
   "name": "my_rl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
